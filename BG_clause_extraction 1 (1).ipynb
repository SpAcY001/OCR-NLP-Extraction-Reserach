{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91f1436d-3d4c-4ea1-bb1c-7038d15532fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.1.8-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages/PyYAML-6.0-py3.10-linux-x86_64.egg (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.4.39)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Downloading aiohttp-3.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n",
      "Collecting async-timeout<5.0.0,>=4.0.0 (from langchain)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
      "  Downloading dataclasses_json-0.6.4-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langchain-community<0.1,>=0.0.21 (from langchain)\n",
      "  Downloading langchain_community-0.0.21-py3-none-any.whl.metadata (8.1 kB)\n",
      "Collecting langchain-core<0.2,>=0.1.24 (from langchain)\n",
      "  Downloading langchain_core-0.1.24-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.0 (from langchain)\n",
      "  Downloading langsmith-0.1.3-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.26.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.10.13)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.31.0)\n",
      "Collecting tenacity<9.0.0,>=8.1.0 (from langchain)\n",
      "  Downloading tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Downloading marshmallow-3.20.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.1)\n",
      "Requirement already satisfied: anyio<5,>=3 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.2,>=0.1.24->langchain) (3.5.0)\n",
      "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2,>=0.1.24->langchain)\n",
      "  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (4.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2023.11.17)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (1.1.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.24->langchain) (1.2.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (0.4.3)\n",
      "Downloading langchain-0.1.8-py3-none-any.whl (816 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m816.1/816.1 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langchain_community-0.0.21-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.1.24-py3-none-any.whl (241 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.3/241.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langsmith-0.1.3-py3-none-any.whl (60 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.5/239.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading marshmallow-3.20.2-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m732.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.3/124.3 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading packaging-23.2-py3-none-any.whl (53 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m746.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.6/301.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: typing-inspect, tenacity, packaging, multidict, jsonpatch, frozenlist, async-timeout, yarl, marshmallow, langsmith, aiosignal, langchain-core, dataclasses-json, aiohttp, langchain-community, langchain\n",
      "  Attempting uninstall: tenacity\n",
      "    Found existing installation: tenacity 8.0.1\n",
      "    Uninstalling tenacity-8.0.1:\n",
      "      Successfully uninstalled tenacity-8.0.1\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 21.3\n",
      "    Uninstalling packaging-21.3:\n",
      "      Successfully uninstalled packaging-21.3\n",
      "  Attempting uninstall: jsonpatch\n",
      "    Found existing installation: jsonpatch 1.32\n",
      "    Uninstalling jsonpatch-1.32:\n",
      "      Successfully uninstalled jsonpatch-1.32\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spyder 5.3.3 requires pyqt5<5.16, which is not installed.\n",
      "spyder 5.3.3 requires pyqtwebengine<5.16, which is not installed.\n",
      "distributed 2022.7.0 requires tornado<6.2,>=6.0.3, but you have tornado 6.4 which is incompatible.\n",
      "jupyterlab 3.4.4 requires jupyter-server~=1.16, but you have jupyter-server 2.12.1 which is incompatible.\n",
      "jupyterlab-server 2.10.3 requires jupyter-server~=1.4, but you have jupyter-server 2.12.1 which is incompatible.\n",
      "notebook 6.5.6 requires jupyter-client<8,>=5.3.4, but you have jupyter-client 8.6.0 which is incompatible.\n",
      "notebook 6.5.6 requires pyzmq<25,>=17, but you have pyzmq 25.1.2 which is incompatible.\n",
      "panel 0.13.1 requires bokeh<2.5.0,>=2.4.0, but you have bokeh 3.3.2 which is incompatible.\n",
      "sagemaker 2.199.0 requires urllib3<1.27, but you have urllib3 2.1.0 which is incompatible.\n",
      "sagemaker-datawrangler 0.4.3 requires sagemaker-data-insights==0.4.0, but you have sagemaker-data-insights 0.3.3 which is incompatible.\n",
      "spyder 5.3.3 requires ipython<8.0.0,>=7.31.1, but you have ipython 8.18.1 which is incompatible.\n",
      "spyder 5.3.3 requires pylint<3.0,>=2.5.0, but you have pylint 3.0.2 which is incompatible.\n",
      "spyder-kernels 2.3.3 requires ipython<8,>=7.31.1; python_version >= \"3\", but you have ipython 8.18.1 which is incompatible.\n",
      "spyder-kernels 2.3.3 requires jupyter-client<8,>=7.3.4; python_version >= \"3\", but you have jupyter-client 8.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed aiohttp-3.9.3 aiosignal-1.3.1 async-timeout-4.0.3 dataclasses-json-0.6.4 frozenlist-1.4.1 jsonpatch-1.33 langchain-0.1.8 langchain-community-0.0.21 langchain-core-0.1.24 langsmith-0.1.3 marshmallow-3.20.2 multidict-6.0.5 packaging-23.2 tenacity-8.2.3 typing-inspect-0.9.0 yarl-1.9.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25a01446-9209-4315-9fea-0d107a8c309d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai==0.28.1\n",
      "  Downloading openai-0.28.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: requests>=2.20 in /opt/conda/lib/python3.10/site-packages (from openai==0.28.1) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from openai==0.28.1) (4.64.1)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from openai==0.28.1) (3.9.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->openai==0.28.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->openai==0.28.1) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->openai==0.28.1) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->openai==0.28.1) (2023.11.17)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai==0.28.1) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai==0.28.1) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai==0.28.1) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai==0.28.1) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai==0.28.1) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->openai==0.28.1) (4.0.3)\n",
      "Downloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.12.0\n",
      "    Uninstalling openai-1.12.0:\n",
      "      Successfully uninstalled openai-1.12.0\n",
      "Successfully installed openai-0.28.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install openai==0.28.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b77296e5-0633-45a5-a6ee-5f504a5b5fa1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.10/site-packages (4.9.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install typing_extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a19fffc8-c14f-42a5-bb76-fc2b42cfd25c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7df3553d-9afe-4fb1-97b2-802b0064a551",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import langchain\n",
    "import os\n",
    "import openai\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain import OpenAI, VectorDBQA\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.prompts import SemanticSimilarityExampleSelector\n",
    "from langchain.vectorstores import Chroma\n",
    "import nltk\n",
    "import dotenv\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain import PromptTemplate\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.schema.document import Document\n",
    "from langchain.chat_models import AzureChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8807a541-5ff6-4c36-be55-96e537383def",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_TYPE\"] = \"azure\"\n",
    "\n",
    "os.environ[\"OPENAI_API_VERSION\"] = \"2023-05-15\"\n",
    "\n",
    "os.environ[\"OPENAI_API_BASE\"] = \"\"\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d9fbc041-c9f3-4b7f-acce-6a499b5aba9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "New_Effective_C= \"\"\" \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9650dbb1-7ed7-4363-b335-a198a20d274a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "New_expiry_C=\"\"\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "999511b1-dd2a-43e7-9dd0-b249acf5840d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "New_Governing_C=\"\"\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a584fe1d-32d6-455a-bcc4-c3fcb4064fde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "New_Transf_C=\"\"\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d088302e-8000-4992-8438-d0f8674fdf85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "New_Nature_Of_BG_C=\"\"\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5340f56-1043-401c-a7de-20e8b8fa2550",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loader = TextLoader(\"bg .txt\")\n",
    "doc=loader.load()\n",
    "\n",
    "import time\n",
    "templates = [ New_Effective_C,New_expiry_C, New_Transf_C, New_Governing_C, New_Nature_Of_BG_C]\n",
    "#templates = [General_template]\n",
    "llm = AzureChatOpenAI(\n",
    "    deployment_name=\"gpt-35-turbo-0301\",\n",
    "    model=\"gpt-3.5-turbo-0301\",\n",
    "    temperature=0\n",
    ")\n",
    "output_text = \" \"\n",
    "for template in templates:\n",
    "    prompt = template.format(context=doc)\n",
    "    time.sleep(2)\n",
    "    answer = llm.predict(prompt)\n",
    "    output_text += answer + \"\\n\\n\"\n",
    "output_file_path = 'Output_111.txt'\n",
    "# Open the file in write mode and write the output\n",
    "with open(output_file_path, 'w') as file:\n",
    "    file.write(output_text)\n",
    "print(output_text)\n",
    "print(\"Output saved successfully\", output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "25252e95-6131-425d-9acb-a86b56dc8265",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file has been created at: output_251.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "file_path = 'Output_111.txt'\n",
    "with open(file_path, 'r') as file:\n",
    "    text_data = file.read()\n",
    "sections = [section.strip() for section in text_data.strip().split('\\n\\n')]\n",
    "data_rows = []\n",
    "common_data = {}  # Store common data fields\n",
    "for section in sections:\n",
    "    section_lines = section.split('\\n')\n",
    "    data_dict = {}\n",
    "    for line in section_lines:\n",
    "        key, value = [item.strip() for item in line.split(':', 1)]\n",
    "        if key == 'Clause name' and value == 'Effectiveness':\n",
    "            value = 'Abisive Claim(Payment)'  \n",
    "        data_dict[key] = value\n",
    "    # Update common data fields if they are not yet populated\n",
    "    if not common_data:\n",
    "        common_data = {key: data_dict[key] for key in ['Document name', 'Benificiary Name', 'Bank name', 'Language']}\n",
    "    data_rows.append(data_dict)\n",
    "csv_file_path = 'output_251.csv'\n",
    "with open(csv_file_path, 'w', newline='') as csvfile:\n",
    "    fieldnames = ['Document name', 'Benificiary Name', 'Bank name', 'Language', 'Clause name', 'Clause description', 'Score', 'Type of Guarantee', 'Feedback']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for row in data_rows:\n",
    "        type_of_guarantee = row.get('Type of Guarantee', '')\n",
    "        if type_of_guarantee.lower() in ['warranty bond', 'performance guarantee', 'performance bond', 'performance bank guarantee', 'warranty guarantee', 'performance guarantee bond', 'Cautionnement de Bonne Exécution']:\n",
    "            clause_description = type_of_guarantee\n",
    "            score = '3'\n",
    "        else:\n",
    "            clause_description = row.get('Clause description', '')\n",
    "            score = re.sub(\"[^0-9]\", \" \", row.get('Score', ''))\n",
    "        # Use common data for \\\"Document name\\\", \\\"Benificiary Name\\\", \\\"Bank name\\\", and \\\"Language\\\"\n",
    "        writer.writerow({\n",
    "            'Document name': common_data.get('Document name', ''),\n",
    "            'Benificiary Name': common_data.get('Benificiary Name', ''),\n",
    "            'Bank name': common_data.get('Bank name', ''),\n",
    "            'Language': common_data.get('Language', ''),\n",
    "            'Clause name': row.get('Clause name', ''),\n",
    "            'Clause description': clause_description,\n",
    "            'Score': score,\n",
    "            'Type of Guarantee': type_of_guarantee,\n",
    "            'Feedback': ''\n",
    "        })\n",
    "print(f'CSV file has been created at: {csv_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6425460-40f7-4845-8b80-cb63471146e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8a4bf5-af9d-4264-ac37-3afee40a91f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Multiple files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "ff19170d-786a-41bb-9c40-07cd3dbf5644",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output saved successfully at Output_combined111.txt\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "folder_path = \"French_Docs\"  # Replace with the path to your folder\n",
    "output_text = \" \"\n",
    "for file in os.listdir(folder_path):\n",
    "    if file.endswith(\".txt\"):\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        loader = TextLoader(file_path)\n",
    "        doc = loader.load()\n",
    "        \n",
    "        templates = [New_Effective_C,New_expiry_C, New_Transf_C, New_Governing_C, New_Nature_Of_BG_C]\n",
    "        \n",
    "        for template in templates:\n",
    "            prompt = template.format(context=doc)\n",
    "            time.sleep(1)\n",
    "            answer = llm.predict(prompt)\n",
    "            output_text += answer + \"\\n\\n\"\n",
    "# Output file path\n",
    "output_file_path = 'Output_combined111.txt'\n",
    "# Open the file in write mode and write the output\n",
    "with open(output_file_path, 'w') as file:\n",
    "    file.write(output_text)\n",
    "print(\"Output saved successfully at\", output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "11cfd551-e918-4938-a6ad-fcbe8dede12e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file has been created at: output_French.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re  # Import the regular expression module for pattern matching\n",
    "# Read input text from a file\n",
    "file_path = 'Output_combined111.txt'\n",
    "with open(file_path, 'r') as file:\n",
    "    text_data = file.read()\n",
    "# Split the text into sections based on empty lines\n",
    "sections = [section.strip() for section in text_data.strip().split('\\n\\n')]\n",
    "# Create a list to store dictionaries representing each row of data\n",
    "data_rows = []\n",
    "# Process each section to extract information\n",
    "for section in sections:\n",
    "    section_lines = section.split('\\n')\n",
    "    data_dict = {}\n",
    "    for line in section_lines:\n",
    "        key, value = [item.strip() for item in line.split(':', 1)]\n",
    "        if key == 'Clause name' and value == 'Effectiveness':\n",
    "            value = 'Abisive Claim(Payment)'  # Replace 'Effectiveness' with 'Abisive claim(Payment)'\n",
    "        data_dict[key] = value\n",
    "    data_rows.append(data_dict)\n",
    "# Extracting the required information and writing to CSV\n",
    "csv_file_path = 'output_French.csv'\n",
    "with open(csv_file_path, 'w', newline='') as csvfile:\n",
    "    fieldnames = ['Document name', 'Benificiary Name', 'Bank name', 'Language', 'Clause name', 'Clause description', 'Score', 'Type of Guarantee','Feedback']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    \n",
    "    writer.writeheader()\n",
    "    for row in data_rows:\n",
    "        type_of_guarantee = row.get('Type of Guarantee', '')\n",
    "        if type_of_guarantee.lower() in ['warranty bond', 'performance guarantee','performance bond', 'performance bank guarantee', 'warranty guarantee','performance guarantee bond','Cautionnement de Bonne Exécution']:\n",
    "            clause_description = type_of_guarantee\n",
    "            score = '3'  # Default score for specific guarantees\n",
    "        else:\n",
    "            clause_description = row.get('Clause description', '')\n",
    "            score = re.sub(\"[^0-9]\", \" \", row.get('Score', ''))  # Extract only numerical values from the score\n",
    "        writer.writerow({\n",
    "            'Document name': row.get('Document name', ''),\n",
    "            'Benificiary Name': row.get('Benificiary Name', ''),\n",
    "            'Bank name': row.get('Bank name', ''),\n",
    "            'Language': row.get('Language', ''),\n",
    "            'Clause name': row.get('Clause name', ''),\n",
    "            'Clause description': clause_description,\n",
    "            'Score': score,\n",
    "            'Type of Guarantee': type_of_guarantee\n",
    "        })\n",
    "print(f'CSV file has been created at: {csv_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e662b62-fe4f-4e14-8eac-04647bc68894",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9d69286f-c2ab-4061-81b6-f1eb43f50542",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file has been created at: output_20.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re  # Import the regular expression module for pattern matching\n",
    "# Read input text from a file\n",
    "file_path = 'Output_111.txt'\n",
    "with open(file_path, 'r') as file:\n",
    "    text_data = file.read()\n",
    "# Split the text into sections based on empty lines\n",
    "sections = [section.strip() for section in text_data.strip().split('\\n\\n')]\n",
    "# Create a list to store dictionaries representing each row of data\n",
    "data_rows = []\n",
    "# Process each section to extract information\n",
    "for section in sections:\n",
    "    section_lines = section.split('\\n')\n",
    "    data_dict = {'Document name': '', 'Benificiary Name': '', 'Bank name': '', 'Language': ''}  # Initialize with empty values\n",
    "    for line in section_lines:\n",
    "        key, value = [item.strip() for item in line.split(':', 1)]\n",
    "        if key == 'Clause name' and value == 'Effectiveness':\n",
    "            value = 'Abisive Claim(Payment)'  # Replace 'Effectiveness' with 'Abisive Claim(Payment)'\n",
    "        data_dict[key] = value\n",
    "    data_rows.append(data_dict)\n",
    "# Extracting the required information and writing to CSV\n",
    "csv_file_path = 'output_20.csv'\n",
    "with open(csv_file_path, 'w', newline='') as csvfile:\n",
    "    fieldnames = ['Document name', 'Benificiary Name', 'Bank name', 'Language', 'Clause name', 'Clause description', 'Score', 'Type of Guarantee', 'Feedback']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    \n",
    "    writer.writeheader()\n",
    "    for row in data_rows:\n",
    "        type_of_guarantee = row.get('Type of Guarantee', '')\n",
    "        if type_of_guarantee.lower() in ['warranty bond', 'performance guarantee', 'performance bond', 'performance bank guarantee', 'warranty guarantee', 'performance guarantee bond', 'Cautionnement de Bonne Exécution']:\n",
    "            clause_description = type_of_guarantee\n",
    "            score = '3'  # Default score for specific guarantees\n",
    "        else:\n",
    "            clause_description = row.get('Clause description', '')\n",
    "            score = re.sub(\"[^0-9]\",\" \", row.get('Score', ''))  # Extract only numerical values from the score\n",
    "        writer.writerow({\n",
    "            'Document name': row.get('Document name', ''),\n",
    "            'Benificiary Name': row.get('Benificiary Name', ''),\n",
    "            'Bank name': row.get('Bank name', ''),\n",
    "            'Language': row.get('Language', ''),\n",
    "            'Clause name': row.get('Clause name', ''),\n",
    "            'Clause description': clause_description,\n",
    "            'Score': score,\n",
    "            'Type of Guarantee': type_of_guarantee,\n",
    "            'Feedback': ''  # Add a placeholder for Feedback\n",
    "        })\n",
    "print(f'CSV file has been created at: {csv_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9be452b-4cc4-457e-b53a-0f4c6bc35224",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "# Read input text from a file\n",
    "file_path = 'Output_combined111.txt'\n",
    "with open(file_path, 'r') as file:\n",
    "    text_data = file.read()\n",
    "# Split the text into sections based on empty lines\n",
    "sections = [section.strip() for section in text_data.strip().split('\\n\\n')]\n",
    "# Create a list to store dictionaries representing each row of data\n",
    "data_rows = []\n",
    "# Process each section to extract information\n",
    "for section in sections:\n",
    "    section_lines = section.split('\\n')\n",
    "    data_dict = {}\n",
    "    for line in section_lines:\n",
    "        key_value_pair = [item.strip() for item in line.split(':', 1)]\n",
    "        if len(key_value_pair) == 2:\n",
    "            key, value = key_value_pair\n",
    "            data_dict[key] = value\n",
    "    if data_dict:  # Add the dictionary to the list only if it's not empty\n",
    "        data_rows.append(data_dict)\n",
    "# Extracting the required information and writing to CSV\n",
    "csv_file_path = 'latest_clause_extraction_French.csv'\n",
    "with open(csv_file_path, 'w', newline='') as csvfile:\n",
    "    fieldnames = ['Document name', 'Benificiary Name', 'Bank name', 'Language', 'Clause name', 'Clause description', 'Score', 'Type of Guarantee']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for row in data_rows:\n",
    "        type_of_guarantee = row.get('Type of Guarantee', '')\n",
    "        if type_of_guarantee.lower() in ['warranty bond', 'performance guarantee', 'performance bond', 'performance bank guarantee', 'warranty guarantee', 'performance guarantee bond']:\n",
    "            clause_description = type_of_guarantee\n",
    "            score = '3'\n",
    "        else:\n",
    "            clause_description = row.get('Clause description', '')\n",
    "            score = re.sub(\"[^0-9]\", \" \", row.get('Score', ''))\n",
    "        writer.writerow({\n",
    "            'Document name': row.get('Document name', ''),\n",
    "            'Benificiary Name': row.get('Benificiary Name', ''),\n",
    "            'Bank name': row.get('Bank name', ''),\n",
    "            'Language': row.get('Language', ''),\n",
    "            'Clause name': row.get('Clause name', ''),\n",
    "            'Clause description': clause_description,\n",
    "            'Score': score,\n",
    "            'Type of Guarantee': type_of_guarantee\n",
    "        })\n",
    "print(f'CSV file has been created at: {csv_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "1621bf61-33ce-4a2a-a8c5-d4dac4d714ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file has been created at: Output_combined111German1.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re  # Import the regular expression module for pattern matching\n",
    "# Read input text from a file\n",
    "file_path = 'Output_combined111.txt'\n",
    "with open(file_path, 'r') as file:\n",
    "    text_data = file.read()\n",
    "# Split the text into sections based on empty lines\n",
    "sections = [section.strip() for section in text_data.strip().split('\\n\\n')]\n",
    "# Process each section to extract information\n",
    "data_rows = []\n",
    "common_data = {}  # Store common data fields\n",
    "for section in sections:\n",
    "    section_lines = section.split('\\n')\n",
    "    data_dict = {}\n",
    "    for line in section_lines:\n",
    "        if ':' in line:\n",
    "            key, value = [item.strip() for item in line.split(':', 1)]\n",
    "            if key == 'Clause name' and value == 'Effectiveness':\n",
    "                value = 'Abisive Claim(Payment)'\n",
    "            data_dict[key] = value\n",
    "    # Update common data fields if they are not yet populated\n",
    "    if not common_data:\n",
    "        common_data = {key: data_dict.get(key, '') for key in ['Document name', 'Benificiary Name', 'Bank name', 'Language']}\n",
    "    data_rows.append(data_dict)\n",
    "# Extracting the required information and writing to CSV\n",
    "csv_file_path = 'Output_combined111German1.csv'\n",
    "with open(csv_file_path, 'w', newline='') as csvfile:\n",
    "    fieldnames = ['Document name', 'Benificiary Name', 'Bank name', 'Language', 'Clause name', 'Clause description', 'Score', 'Type of Guarantee']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for row in data_rows:\n",
    "        type_of_guarantee = row.get('Type of Guarantee', '')\n",
    "        if type_of_guarantee.lower() in ['warranty bond', 'performance guarantee', 'performance bond', 'performance bank guarantee', 'warranty guarantee', 'performance guarantee bond', 'Cautionnement de Bonne Exécution']:\n",
    "            clause_description = type_of_guarantee\n",
    "            score = '3'  # Default score for specific guarantees\n",
    "        else:\n",
    "            clause_description = row.get('Clause description', '')\n",
    "            score = re.sub(\"[^0-9]\", \" \", row.get('Score', ''))  # Extract only numerical values from the score\n",
    "        writer.writerow({\n",
    "            'Document name': common_data.get('Document name', ''),\n",
    "            'Benificiary Name': common_data.get('Benificiary Name', ''),\n",
    "            'Bank name': common_data.get('Bank name', ''),\n",
    "            'Language': common_data.get('Language', ''),\n",
    "            'Clause name': row.get('Clause name', ''),\n",
    "            'Clause description': clause_description,\n",
    "            'Score': score,\n",
    "            'Type of Guarantee': type_of_guarantee\n",
    "        })\n",
    "print(f'CSV file has been created at: {csv_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "20a2bfe3-bbc0-4ffa-a356-f4b500b2094a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file has been created at: Output_combined111German11111.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "file_path = 'Output_combined111.txt'\n",
    "with open(file_path, 'r') as file:\n",
    "    text_data = file.read()\n",
    "sections = [section.strip() for section in text_data.strip().split('\\n\\n')]\n",
    "data_rows = []\n",
    "common_data = {}\n",
    "for section in sections:\n",
    "    section_lines = section.split('\\n')\n",
    "    data_dict = {}\n",
    "    for line in section_lines:\n",
    "        if ':' in line:  # Check if the line contains the delimiter \\\":\\\"\n",
    "            key, value = [item.strip() for item in line.split(':', 1)]\n",
    "            if key == 'Clause name' and value == 'Effectiveness':\n",
    "                value = 'Abisive Claim(Payment)'\n",
    "            data_dict[key] = value\n",
    "    if not common_data:\n",
    "        common_data = {key: data_dict[key] for key in ['Document name', 'Benificiary Name', 'Bank name', 'Language']}\n",
    "    data_dict.update(common_data)  # Populate common fields for each record\n",
    "    data_rows.append(data_dict)\n",
    "csv_file_path = 'Output_combined111German11111.csv'\n",
    "with open(csv_file_path, 'w', newline='') as csvfile:\n",
    "    fieldnames = ['Document name', 'Benificiary Name', 'Bank name', 'Language', 'Clause name', 'Clause description', 'Score', 'Type of Guarantee', 'Feedback']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for row in data_rows:\n",
    "        type_of_guarantee = row.get('Type of Guarantee', '')\n",
    "        if type_of_guarantee.lower() in ['warranty bond', 'performance guarantee', 'performance bond', 'performance bank guarantee', 'warranty guarantee', 'performance guarantee bond', 'Cautionnement de Bonne Exécution']:\n",
    "            clause_description = type_of_guarantee\n",
    "            score = '3'  # Default score for specific guarantees\n",
    "        else:\n",
    "            clause_description = row.get('Clause description', '')\n",
    "            score = re.sub(\"[^0-9]\", \" \", row.get('Score', ''))  # Extract only numerical values from the score\n",
    "        writer.writerow({\n",
    "            'Document name': row.get('Document name', ''),\n",
    "            'Benificiary Name': row.get('Benificiary Name', ''),\n",
    "            'Bank name': row.get('Bank name', ''),\n",
    "            'Language': row.get('Language', ''),\n",
    "            'Clause name': row.get('Clause name', ''),\n",
    "            'Clause description': clause_description,\n",
    "            'Score': score,\n",
    "            'Type of Guarantee': type_of_guarantee\n",
    "        })\n",
    "print(f'CSV file has been created at: {csv_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cccc6ab4-539a-4b86-a90c-10da431de409",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "translate = boto3.client('translate', aws_access_key_id=\"AKIARU3MIISFVHPQBHLV\", aws_secret_access_key=\"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\")\n",
    "val=\"Cautionnement de Bonne ExÃ©cution\"\n",
    "result = translate.translate_text(Text=val, SourceLanguageCode=\"fr\", TargetLanguageCode=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4661d7a-b74b-4331-9a74-fa33f23da3a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:470317259841:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
